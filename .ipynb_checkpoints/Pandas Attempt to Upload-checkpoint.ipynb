{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ddb67a5",
   "metadata": {},
   "source": [
    "You need to change the File and Table Name for every table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb6d8475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import pandas_gbq\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af4beb2",
   "metadata": {},
   "source": [
    "I don't think you actually have to run this code, but im keeping it here so I can come get it later when I need it for part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78713025",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_path = \"D:\\\\gradschool\\\\ADA\\\\Wedge\\\\\"\n",
    "service_file = \"joynerwedge-c56d6d56d47d.json\"\n",
    "gbq_proj_id = \"joynerwedge\"\n",
    "gbq_dataset_id =\"JoynerWedgeV2\"\n",
    "\n",
    "private_key = service_path + service_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d31fee",
   "metadata": {},
   "source": [
    "Same thing here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e9d977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your credentials\n",
    "credentials = service_account.Credentials.from_service_account_file(service_path + service_file)\n",
    "\n",
    "# And create a client to talk to GBQ\n",
    "client = bigquery.Client(credentials = credentials, project=gbq_proj_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6693edf2",
   "metadata": {},
   "source": [
    "You don't need to run this, Its just there if you want to run everything manually. I did it my first time, It sucked ass, run the automated part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4d7ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in one file to a data frame, then making a headers for the data\n",
    "df = pd.read_csv('transArchive_201204_201206_clean.csv', names =['DateTime','Register_Num','Emp_Num',\"Trans_Num\", \"UPC\",\"Description\",'Trans_Type',\"Trans_SubType\",'Trans_Status',\n",
    "                                                                 'Department','Quantity','Scale','Cost','Unit_Price','Total','Reg_Price','Alt_Price','Tax',\n",
    "                                                                 \"TaxExempt\",'Foodstamp','WicAble','Discount','memDiscount','Discountable','DiscountType',\n",
    "                                                                 'Voided','PercentDiscount','ItemQtty','volDiscType','Volume','VolSpecial','mixMatch','Matched'\n",
    "                                                                 ,'MemType','Staff','NumFlag','itemStatus','TenderStatus','CharFlag','varflag','BatchHeaderID','Local',\n",
    "                                                                 'Organic','Display','Receipt','Card_No','Store','Branch','Match_ID','Trans_ID'])\n",
    "\n",
    "\n",
    "cols_to_bool = [\"MemType\", \"Staff\", \"BatchHeaderID\", \"Display\"]\n",
    "df[cols_to_bool] = df[cols_to_bool].astype('bool')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a78217e0",
   "metadata": {},
   "source": [
    "Here is the pandas to gbq portion.\n",
    "You don't need to run this, Its just there if you want to run everything manually. I did it my first time, It sucked ass, run the automated part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208722ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the total amount of stuff you can put in the code, keeping it here for future reference\n",
    "#DataFrame.to_gbq(destination_table, project_id=None, chunksize=None, reauth=False,\n",
    "#if_exists='fail', auth_local_webserver=False,\n",
    "#table_schema=None, location=None, progress_bar=True, credentials=None)\n",
    "DataFrame.to_gbq(df,\"joynerwedge.JoynerWedgev2.transArchive_201307_201309_inactive_clean_test\",gbq_proj_id,chunksize = 500000, if_exists = \"replace\",\n",
    " table_schema = \n",
    "[{'name': 'DateTime', 'type': 'Timestamp'}, {'name': 'Register_Num', 'type': 'Float'},\n",
    "{'name': 'Emp_Num', 'type': 'Float'}, {'name': 'Trans_Num', 'type': 'Float'},\n",
    "{'name': 'UPC', 'type': 'string'}, {'name': 'Description', 'type': 'string'},\n",
    "{'name': 'Trans_Type', 'type': 'string'}, {'name': 'Trans_SubType', 'type': 'string'},\n",
    "{'name': 'Trans_Status', 'type': 'string'}, {'name': 'Department', 'type': 'Float'},\n",
    "{'name': 'Quantity', 'type': 'float'}, {'name': 'Scale', 'type': 'Float'},\n",
    "{'name': 'Cost', 'type': 'float'}, {'name': 'Unit_Price', 'type': 'float'},\n",
    "{'name': 'Total', 'type': 'float'}, {'name': 'Reg_Price', 'type': 'float'},\n",
    "{'name': 'Alt_Price', 'type': 'float'}, {'name': 'Tax', 'type': 'float'},\n",
    "{'name': 'TaxExempt', 'type': 'float'}, {'name': 'Foodstamp', 'type': 'Float'},\n",
    "{'name': 'WicAble', 'type': 'Float'}, {'name': 'Discount', 'type': 'float'},\n",
    "{'name': 'memDiscount', 'type': 'float'}, {'name': 'Discountable', 'type': 'float'},\n",
    "{'name': 'DiscountType', 'type': 'float'}, {'name': 'Voided', 'type': 'float'},\n",
    "{'name': 'PercentDiscount', 'type': 'float'}, {'name': 'ItemQtty', 'type': 'float'},\n",
    "{'name': 'volDiscType', 'type': 'float'}, {'name': 'Volume', 'type': 'float'},\n",
    "{'name': 'VolSpecial', 'type': 'float'}, {'name': 'mixMatch', 'type': 'float'},\n",
    "{'name': 'Matched', 'type': 'float'}, {'name': 'MemType', 'type': 'Boolean'},\n",
    "{'name': 'Staff', 'type': 'Boolean'}, {'name': 'NumFlag', 'type': 'float'},\n",
    "{'name': 'itemStatus', 'type': 'float'}, {'name': 'TenderStatus', 'type': 'float'},\n",
    "{'name': 'CharFlag', 'type': 'string'}, {'name': 'varFlag', 'type': 'float'},\n",
    "{'name': 'BatchHeaderID', 'type': 'boolean'}, {'name': 'Local', 'type': 'float'},\n",
    "{'name': 'Organic', 'type': 'float'}, {'name': 'Display', 'type': 'Boolean'},\n",
    "{'name': 'Receipt', 'type': 'float'}, {'name': 'Card_No', 'type': 'float'},\n",
    "{'name': 'Store', 'type': 'float'}, {'name': 'Branch', 'type': 'float'},\n",
    "{'name': 'Match_ID', 'type': 'float'}, {'name': 'Trans_ID', 'type': 'float'}])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509cca1",
   "metadata": {},
   "source": [
    "Start running this code for automation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22c9da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a list that we can run through of the clean files\n",
    "files = []\n",
    "location = os.listdir(\"clean-files\")\n",
    "for item in location:\n",
    "    files.append(item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c791759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacks\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (33) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "WARNING:google.auth.compute_engine._metadata:Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [WinError 10051] A socket operation was attempted to an unreachable network\n",
      "WARNING:google.auth.compute_engine._metadata:Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [WinError 10051] A socket operation was attempted to an unreachable network\n",
      "WARNING:google.auth.compute_engine._metadata:Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [WinError 10051] A socket operation was attempted to an unreachable network\n",
      "WARNING:google.auth._default:Authentication failed using Compute Engine authentication due to unavailable metadata server.\n",
      "7it [11:46, 100.94s/it]\n",
      "1it [00:59, 59.56s/it]\n",
      "6it [12:17, 122.91s/it]\n",
      "1it [00:54, 54.54s/it]\n",
      "6it [13:31, 135.21s/it]\n",
      "1it [00:43, 43.10s/it]\n",
      "6it [17:04, 170.77s/it]\n",
      "1it [00:34, 34.28s/it]\n",
      "7it [12:03, 103.39s/it]\n",
      "1it [00:32, 32.73s/it]\n",
      "6it [12:08, 121.40s/it]\n",
      "1it [00:27, 27.25s/it]\n",
      "C:\\Users\\jacks\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (33,43) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "6it [11:57, 119.55s/it]\n",
      "1it [00:23, 23.47s/it]\n",
      "6it [11:39, 116.65s/it]\n",
      "C:\\Users\\jacks\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (43) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "1it [00:18, 18.85s/it]\n",
      "7it [12:33, 107.59s/it]\n",
      "1it [00:17, 17.85s/it]\n",
      "7it [12:48, 109.82s/it]\n",
      "1it [00:09,  9.30s/it]\n",
      "6it [11:53, 118.85s/it]\n",
      "1it [00:04,  4.11s/it]\n",
      "7it [11:53, 101.98s/it]\n",
      "7it [12:54, 110.63s/it]\n",
      "7it [11:25, 97.87s/it] \n",
      "3it [03:35, 71.98s/it]\n",
      "2it [03:40, 110.33s/it]\n",
      "2it [04:23, 131.71s/it]\n",
      "2it [04:00, 120.30s/it]\n",
      "2it [03:20, 100.40s/it]\n",
      "2it [03:36, 108.39s/it]\n",
      "2it [03:27, 103.60s/it]\n",
      "2it [03:48, 114.27s/it]\n",
      "2it [03:04, 92.03s/it]\n",
      "2it [03:36, 108.45s/it]\n",
      "2it [03:25, 102.95s/it]\n",
      "2it [03:25, 102.70s/it]\n",
      "2it [03:37, 108.78s/it]\n",
      "2it [03:33, 106.53s/it]\n",
      "2it [03:31, 105.68s/it]\n",
      "2it [03:52, 116.11s/it]\n"
     ]
    }
   ],
   "source": [
    "projID = \"JoynerWedgeV3.\"\n",
    "# The loop that goes through each file and adds it to the data frame\n",
    "for item in files:\n",
    "    TableName = projID + item[:-4]\n",
    "    df = pd.read_csv( item, names =['DateTime','Register_Num','Emp_Num',\"Trans_Num\", \"UPC\",\"Description\",'Trans_Type',\"Trans_SubType\",'Trans_Status',\n",
    "                                                                 'Department','Quantity','Scale','Cost','Unit_Price','Total','Reg_Price','Alt_Price','Tax',\n",
    "                                                                 \"TaxExempt\",'Foodstamp','WicAble','Discount','memDiscount','Discountable','DiscountType',\n",
    "                                                                 'Voided','PercentDiscount','ItemQtty','volDiscType','Volume','VolSpecial','mixMatch','Matched'\n",
    "                                                                 ,'MemType','Staff','NumFlag','itemStatus','TenderStatus','CharFlag','varflag','BatchHeaderID','Local',\n",
    "                                                                 'Organic','Display','Receipt','Card_No','Store','Branch','Match_ID','Trans_ID'])\n",
    "    cols_to_bool = [\"MemType\", \"Staff\", \"BatchHeaderID\", \"Display\"]\n",
    "    df[cols_to_bool] = df[cols_to_bool].astype('bool')\n",
    "\n",
    "    \n",
    "    # Takes the Dataframe and sends it to GBQ\n",
    "    DataFrame.to_gbq(df,TableName,gbq_proj_id,chunksize  = 500000, if_exists = \"replace\",table_schema = \n",
    "    [{'name': 'DateTime', 'type': 'Timestamp'}, {'name': 'Register_Num', 'type': 'Float'},\n",
    "    {'name': 'Emp_Num', 'type': 'Float'}, {'name': 'Trans_Num', 'type': 'Float'},\n",
    "    {'name': 'UPC', 'type': 'string'}, {'name': 'Description', 'type': 'string'},\n",
    "    {'name': 'Trans_Type', 'type': 'string'}, {'name': 'Trans_SubType', 'type': 'string'},\n",
    "    {'name': 'Trans_Status', 'type': 'string'}, {'name': 'Department', 'type': 'Float'},\n",
    "    {'name': 'Quantity', 'type': 'float'}, {'name': 'Scale', 'type': 'Float'},\n",
    "    {'name': 'Cost', 'type': 'float'}, {'name': 'Unit_Price', 'type': 'float'},\n",
    "    {'name': 'Total', 'type': 'float'}, {'name': 'Reg_Price', 'type': 'float'},\n",
    "    {'name': 'Alt_Price', 'type': 'float'}, {'name': 'Tax', 'type': 'float'},\n",
    "    {'name': 'TaxExempt', 'type': 'float'}, {'name': 'Foodstamp', 'type': 'Float'},\n",
    "    {'name': 'WicAble', 'type': 'Float'}, {'name': 'Discount', 'type': 'float'},\n",
    "    {'name': 'memDiscount', 'type': 'float'}, {'name': 'Discountable', 'type': 'float'},\n",
    "    {'name': 'DiscountType', 'type': 'float'}, {'name': 'Voided', 'type': 'float'},\n",
    "    {'name': 'PercentDiscount', 'type': 'float'}, {'name': 'ItemQtty', 'type': 'float'},\n",
    "    {'name': 'volDiscType', 'type': 'float'}, {'name': 'Volume', 'type': 'float'},\n",
    "    {'name': 'VolSpecial', 'type': 'float'}, {'name': 'mixMatch', 'type': 'float'},\n",
    "    {'name': 'Matched', 'type': 'float'}, {'name': 'MemType', 'type': 'Boolean'},\n",
    "    {'name': 'Staff', 'type': 'Boolean'}, {'name': 'NumFlag', 'type': 'float'},\n",
    "    {'name': 'itemStatus', 'type': 'float'}, {'name': 'TenderStatus', 'type': 'float'},\n",
    "    {'name': 'CharFlag', 'type': 'string'}, {'name': 'varFlag', 'type': 'float'},\n",
    "    {'name': 'BatchHeaderID', 'type': 'boolean'}, {'name': 'Local', 'type': 'float'},\n",
    "    {'name': 'Organic', 'type': 'float'}, {'name': 'Display', 'type': 'Boolean'},\n",
    "    {'name': 'Receipt', 'type': 'float'}, {'name': 'Card_No', 'type': 'float'},\n",
    "    {'name': 'Store', 'type': 'float'}, {'name': 'Branch', 'type': 'float'},\n",
    "    {'name': 'Match_ID', 'type': 'float'}, {'name': 'Trans_ID', 'type': 'float'}])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
