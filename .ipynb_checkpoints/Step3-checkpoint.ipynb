{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7686162",
   "metadata": {},
   "source": [
    "This File will make summary tables for the Wedge DB. After the tables are made, they will be sent to a local DataBase that is created in this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c7116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import random\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import pandas_gbq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a578d1e9",
   "metadata": {},
   "source": [
    "You will need to provide your own service path, service file, gbq project id, and dataset id. I have redacted mine so you can add yours into the quotation marks below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78298e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_path = \"\"\n",
    "service_file = \"\"\n",
    "gbq_proj_id = \"\"\n",
    "gbq_dataset_id =\"\"\n",
    "\n",
    "private_key = service_path + service_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e78b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your credentials\n",
    "credentials = service_account.Credentials.from_service_account_file(service_path + service_file)\n",
    "\n",
    "# And create a client to talk to GBQ\n",
    "client = bigquery.Client(credentials = credentials, project=gbq_proj_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44586729",
   "metadata": {},
   "source": [
    "Here are all of the querys needed to complete this section. Note: The third query still needs some work after we get it into the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f6b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry1 = \"\"\"SELECT (EXTRACT(date FROM datetime)) AS Date,\n",
    "    (EXTRACT(HOUR FROM datetime)) AS Hour,\n",
    "    SUM(total) as Sales,\n",
    "    COUNT(DISTINCT(Date(datetime) || Register_Num || Emp_Num || Trans_Num)) AS Transactions,\n",
    "    SUM(CASE WHEN(Trans_Status = 'V' OR Trans_Status = 'R') THEN -1 ELSE 1 END) as Items\n",
    "    FROM `joynerwedge.JoynerWedgeV3.transArchive*`\n",
    "    \n",
    "    WHERE Card_No != 3\n",
    "    AND department != 0\n",
    "    AND department != 15\n",
    "    AND trans_status != 'M'\n",
    "    AND trans_status != 'C'\n",
    "    AND trans_status != 'J'\n",
    "    AND (trans_status = ''\n",
    "    OR trans_status = ' '\n",
    "    OR trans_status = 'V'\n",
    "    OR trans_status = 'R')\n",
    "    GROUP BY Date, Hour\n",
    "    ORDER BY Date, Hour\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead7f5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry2 = \"\"\"SELECT card_no,\n",
    "    (EXTRACT(year FROM datetime)) AS Year,\n",
    "    (EXTRACT(month FROM datetime)) AS Month,\n",
    "    SUM(total) as Sales,\n",
    "    COUNT(DISTINCT(Date(datetime) || Register_Num || Emp_Num || Trans_Num)) AS Transactions,\n",
    "    SUM(CASE WHEN(trans_status = 'V' OR trans_status = 'R') THEN -1 ELSE 1 END) as Items\n",
    "    FROM `joynerwedge.JoynerWedgeV3.transArchive*`\n",
    "\n",
    "    WHERE department != 0\n",
    "    AND department != 15\n",
    "    AND trans_status != 'M'\n",
    "    AND trans_status != 'C'\n",
    "    AND trans_status != 'J'\n",
    "    AND (trans_status = ''\n",
    "    OR trans_status = ' '\n",
    "    OR trans_status = 'V'\n",
    "    OR trans_status = 'R')\n",
    "    GROUP BY card_no, Year, Month\n",
    "    ORDER BY card_no, Year, Month\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccccd4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry3 = \"\"\"SELECT\n",
    "    (EXTRACT(year FROM datetime)) AS Year,\n",
    "    (EXTRACT(month FROM datetime)) AS Month,\n",
    "    upc,\n",
    "    description,\n",
    "    p1.department AS dept_no,\n",
    "    SUM(total) as Sales,\n",
    "    COUNT(DISTINCT(Date(datetime) || register_num || emp_num || trans_num)) AS Transactions,\n",
    "    SUM(CASE WHEN(trans_status = 'V' OR trans_status = 'R') THEN -1 ELSE 1 END) as Items\n",
    "    FROM `joynerwedge.JoynerWedgeV3.transArchive*` AS p1\n",
    "    \n",
    "    LEFT OUTER JOIN `joynerwedge.JoynerWedgeV3.DepartmentLookup` AS dl ON p1.department = dl.department\n",
    "    \n",
    "    WHERE card_no != 3\n",
    "    AND p1.department != 0\n",
    "    AND p1.department != 15\n",
    "    AND trans_status != 'M'\n",
    "    AND trans_status != 'C'\n",
    "    AND trans_status != 'J'\n",
    "    AND (trans_status = ''\n",
    "    OR trans_status = ' '\n",
    "    OR trans_status = 'V'\n",
    "    OR trans_status = 'R')\n",
    "    GROUP BY Year, Month, upc, description, dept_no\n",
    "    ORDER BY description, Year, Month DESC\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6790c558",
   "metadata": {},
   "source": [
    "Now we add each query into a Dataframe via pd.read-gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6da279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas.read_gbq(query, project_id=None, index_col=None, col_order=None, reauth=False,\n",
    "#auth_local_webserver=False, dialect=None, location=None, configuration=None, credentials=None,\n",
    "#use_bqstorage_api=None, max_results=None, progress_bar_type=None)\n",
    "df1 = pd.read_gbq(qry1,gbq_proj_id)\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb295d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_gbq(qry2,gbq_proj_id)\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686efe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_gbq(qry3,gbq_proj_id)\n",
    "df3.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac3122d",
   "metadata": {},
   "source": [
    "Now that all of the data is in the DataFrames, lets fix the third dataframe so that we have department names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3297651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I got the inspiration for this code from  https://stackoverflow.com/questions/26886653/pandas-create-new-column-based-on-values-from-other-columns-apply-a-function-o\n",
    "def dept_name (row):\n",
    "    if row['dept_no'] == 1.0:\n",
    "        return \"Packaged Grocery\"\n",
    "    if row['dept_no'] == 2.0:\n",
    "        return \"Produce\"\n",
    "    if row['dept_no'] == 3.0:\n",
    "        return \"Bulk\"\n",
    "    if row['dept_no'] == 4.0:\n",
    "        return \"Ref Grocery\"\n",
    "    if row['dept_no'] == 5.0:\n",
    "        return \"Cheese\"\n",
    "    if row['dept_no'] == 6.0:\n",
    "        return \"Frozen\"\n",
    "    if row['dept_no'] == 7.0:\n",
    "        return \"Bread\"\n",
    "    if row['dept_no'] == 8.0:\n",
    "        return \"Deli\"\n",
    "    if row['dept_no'] == 9.0:\n",
    "        return \"Gen Merch\"\n",
    "    if row['dept_no'] == 10.0:\n",
    "        return \"Supplements\"\n",
    "    if row['dept_no'] == 11.0:\n",
    "        return \"Personal Care\"\n",
    "    if row['dept_no'] == 12.0:\n",
    "        return \"Herbs & Spices\"\n",
    "    if row['dept_no'] == 13.0:\n",
    "        return \"Meat\"\n",
    "    if row['dept_no'] == 14.0:\n",
    "        return \"Juice Bar\"\n",
    "    if row['dept_no'] == 15.0:\n",
    "        return \"Misc P/I\"\n",
    "    if row['dept_no'] == 16.0:\n",
    "        return \"Fish & Seafood\"\n",
    "    if row['dept_no'] == 17.0:\n",
    "        return \"Bakehouse\"\n",
    "    if row['dept_no'] == 18.0:\n",
    "        return \"Flowers\"\n",
    "    if row['dept_no'] == 19.0:\n",
    "        return \"WedgeWorldWide\"\n",
    "    if row['dept_no'] == 20.0:\n",
    "        return \"Misc P/I WWW\"\n",
    "    if row['dept_no'] == 21.0:\n",
    "        return \"Catering\"\n",
    "    if row['dept_no'] == 22.0:\n",
    "        return \"Beer & Wine\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ace053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This adds the column and its contents to the dataframe\n",
    "df3['Dept_Name'] = df3.apply (lambda row: dept_name(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c58f981",
   "metadata": {},
   "outputs": [],
   "source": [
    "   df3.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeb98fb",
   "metadata": {},
   "source": [
    "Now that the Dataframe has the department names, we can send it to the database, but we need to make the database first. Making the DB and adding the first dataframe to the db will happen in the first cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1979188",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('Wedge_Task3.db')\n",
    "#DataFrame.to_sql(name, con, schema=None, if_exists='fail',\n",
    "#index=True, index_label=None, chunksize=None, dtype=None, method=None) \n",
    "#This is the syntax for what we are doing\n",
    "df1.to_sql(\"Output1\",db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9734900",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_sql(\"Output2\",db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db5b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_sql(\"Output3\",db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
